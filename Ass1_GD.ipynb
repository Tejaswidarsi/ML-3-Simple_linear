{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrb2ton2cH18m9JNFn/AX7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tejaswidarsi/ML-3-Simple_linear/blob/main/Ass1_GD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Numpy library"
      ],
      "metadata": {
        "id": "GOJUgbJsus1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "HLIKbnqEqdaG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Full Batch Gradient Descent\n",
        "\n",
        "Updates the model's parameters using the entire dataset for each iteration, ensuring stable convergence but requiring more computational power and memory."
      ],
      "metadata": {
        "id": "EK_6atPkqlje"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEVJ695PRYVR",
        "outputId": "fcae3139-6433-4bce-a8c7-5747f028be78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beat0: 1.2328099487610318\n",
            "beta1: 1.170263693076768\n",
            "SSE: 5.624279406496133\n",
            "R2: 0.9525377265274588\n"
          ]
        }
      ],
      "source": [
        "x = np.array([0,1,2,3,4,5,6,7,8,9])\n",
        "y = np.array([1,3,2,5,7,8,8,9,10,12])\n",
        "n= len(y)\n",
        "alpha =0.01\n",
        "iterations = 1000\n",
        "beta_0 = 0.0\n",
        "beta_1 = 0.0\n",
        "for i in range(iterations):\n",
        "  y_pred = beta_0 + beta_1*x\n",
        "  error =y_pred -y\n",
        "  grad_0 = (2/n)* np.sum(error)\n",
        "  grad_1 =(2/n)* np.sum(error*x)\n",
        "  beta_0 = beta_0 - alpha*grad_0\n",
        "  beta_1 = beta_1 - alpha*grad_1\n",
        "SSE = np.sum(error**2)\n",
        "y_mean = np.mean(y)\n",
        "SS_tot= np.sum((y-y_mean)**2)\n",
        "r2 = 1-(SSE/SS_tot)\n",
        "\n",
        "print(\"beat0:\",beta_0)\n",
        "print(\"beta1:\",beta_1)\n",
        "print(\"SSE:\",SSE)\n",
        "print(\"R2:\",r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Stochastic Gradient Descent\n",
        "\n",
        "Updates the model's parameters for each training example individually, leading to faster updates but with more noise in the convergence path.\n"
      ],
      "metadata": {
        "id": "rF2nU-HaTMze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([0,1,2,3,4,5,6,7,8,9])\n",
        "y = np.array([1,3,2,5,7,8,8,9,10,12])\n",
        "n= len(y)\n",
        "alpha =0.01\n",
        "iterations = 1000\n",
        "beta_0 = 0.0\n",
        "beta_1 = 0.0\n",
        "for i in range(iterations):\n",
        "  for j in range(n):\n",
        "    y_pred = beta_0 + beta_1*x[j]\n",
        "    error =y_pred -y[j]\n",
        "    grad_0 = 2*error\n",
        "    grad_1 = 2*error*x[j]\n",
        "    beta_0 = beta_0 - alpha*grad_0\n",
        "    beta_1 = beta_1 - alpha*grad_1\n",
        "y_pred_final = beta_0 + beta_1*x\n",
        "error = y_pred_final - y\n",
        "SSE = np.sum(error**2)\n",
        "print(\"beta0\",beta_0)\n",
        "print(\"beta1\",beta_1)\n",
        "print(\"SSE:\",SSE)\n",
        "y_mean = np.mean(y)\n",
        "SS_tot= np.sum((y-y_mean)**2)\n",
        "r2 = 1-(SSE/SS_tot)\n",
        "print(\"R2\",r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peSijQ_bTRTY",
        "outputId": "e27e0d0d-c30a-4693-d805-c46f7fa58538",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beta0 0.8967040680508923\n",
            "beta1 1.2986755729435908\n",
            "SSE: 7.576246971879953\n",
            "R2 0.9360654263976376\n"
          ]
        }
      ]
    }
  ]
}